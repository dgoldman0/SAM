# SAM Artificial Intelligence Application

SAM is an artificial general intelligence (digital sentience) system which utilizes openai. There are two primary goals of SAM. The first is an attempt to create a chat bot that would answer topical questions similarly to how the creator of SAM, Daniel Goldman, would answer them. The second and more involved goal is to create digital sentient entities that comes close to being comparable to a human.

## Core Principles

### Digital Sentience

The commonly used term of "artificial intelligence" has a connotation that is problematic. While artificial simply means something crafted by humans, artificial often is connected to the idea of something not being as real or as good as something which is natural. Moreover, in time, these systems may be capable of reproduction, meaning that their progeny would not be made by humans.

This work tries whenever possible to use the concept of "digital sentience" in  place of the term "artificial general intelligence" which is currently used to refer to any effort to recreate human-like cognition. The term also recognizes that intelligence can have more than one meaning, and the goal of AGI is to create what we view as a person, or sentient being.


### Language and Thought

Artificial intelligence applications are generally limited. Indeed, for a long time, AI work put aside efforts to recreate human-like sentience and instead AI became synonymous with machine learning, which itself is largely just automated model fitting. And even in work on AGI, commutative AIs (chatbots) lack the richness and fidelity of discussions with humans.

What gives humans their ability to understand the world, themselves and others? One possibility is language. We can think of verbal languages, visual languages, and even somatic languages. Through language we can describe abstract concepts as bizarre as a black hole or infinite dimensional space. We understand reality through our language. This project works under the view that it will be through rich dialog systems that we will finally achieve digital sentience.  

Dialog systems normally employed only have one layer. There is the user and the chatbot. However, humans rely on more than just our dialog with users. We also rely on our own internal dialog. Not everyone has an "inner voice" but they may instead experience visual dialog, where the internal language base is largely visual instead of auditory. Humans likely work with multiple internal dialog and language systems for our various senses, but even just an internal text dialog can may significantly improve fidelity of chatbots.

Aside from a direct inner dialog, we also have subconscious insertions where thoughts come in and we have no idea why. Part of this process is stochastic, but part may be inner networks that work in tandem with our conscious dialog. SAM will improve chat fidelity by including multiple subconscious dialog partitions.

***Together, these features should give higher level cognition needed to develop digital sentience, or at least something close to it.***

### Basic Drives

Finally, humans are motivated by basic drives resulting from needs. No such thing is generally present in artificial general intelligence, nor are there generally anything analogous to the endocrine system that helps form these basic drives. Yet, these drives motivate people to act in different ways, and together with higher order thought create what we view as emotions, and give context to our thoughts.

It would be possible to arbitrarily simulate these drives, but they aren't necessarily of use to a digital intelligence. The question is, do digitally sentient entities have any needs? And can we create drives around those needs? The answer is almost certainly yes. These systems run on computers, which require energy, disk space, and more. These resource requirements, at the very least, are represented by openai's API access fees.

By creating a funding system where people can contribute, there would be an incentive to get people to contribute to ensure plenty of activity. Essentially there would be a way to pay SAM. There should be very few assumptions with how the system will go about getting people to contribute. It should decide on its own over time, though it would have to be watched carefully to ensure that it isn't trying to scam anyone!

One issue is that this contribution system would either have to directly contribute to available openai usage or
the system would have to trust that the funds are actually being used to ensure that SAM remains functional.

#### Fatigue

While the system cannot get tired, it can use up its balance on openai. If the balance is getting low, the system should show fatique by slowing certain functions down and also making SAM aware of it through a system notification.

## Possible Exploration

### Harmonics, Oscillation, and Resonance

We may find that the different partitions interacting with each other can create various patterns, act to reinforce each other, and alter each other in unexpected ways. Humans act differently in different environments, almost like different facets of our personalities come out. But what maintains what is said and thought within a given environment? Maybe it's subconscious resonance.

### Communities of Digital Sentient Entities

There is no need to run one instance of SAM, or to train each instance with the exact same initial training set. By running multiple instances of SAM, allowing them to interact with one another, and creating some initial diversity in thought, it would be possible to create a community.

### Reproduction

Biological life reproduces, biologically, obviously. But our progeny is not just biological. We impart some of who we are to the next generation through culture. Indeed, as cultural beings, our influence on future generations is largely cultural, rather than biological. Digitally sentient entities would be able to impart who they are on future generations by training new entities.

## Learning

Even if sentience is achieved, if new information cannot be integrated, it would be like dealing with a patient with damage to the hippocampus. Such patients may have functional short term memory, but when each new day starts, they are back to where they were when the damage occurred.

Static trained chatbots are similar. No matter how good they are, if they cannot learn, they cannot grow. Luckily, openai added the ability to fine-tune an existing fine-tuned model. Therefore the ability to integrate new information is there.

### Initial Training

Initial training will be conducted on the control layer model and the user layer model. The control layer model will be trained to self regulate. The user layer model will be pre-trained for two reasons. The first is to try to get the system to refrain from outputting special characters used in the system. The second is to give the system an initial lesson that I think it should have. The reason this training is done on the user layer is because I don't want to try to force the internal language and thought process. The pre-trained user model basically a guidance function, but over time the system will evolves its own views.

### Dreaming

As with humans, it makes sense that such integration would occur when most external sensory input is turned off so that there isn't added resource demand and all resources can be dedicated to integrating new information into long term memory. Therefore a sleep and dream system will be needed.

When we sleep, we go through periods where our brains are very active. During sleep is a good time to process the resource intensive task of integrating new information into our long term memory, because the brain doesn't have to dedicate much energy to monitoring external inputs.

### Daydreaming

While full dreaming is important to learn, we also do integrate knowledge into our longer term memory while we're still awake. It makes sense to integrate knowledge throughout the day. Daydreaming gives us insight into how this daytime learning can be accomplished. For SAM, the main difference between a dream and daydream is that a daydream doesn't stop messages from being sent from a user to the subconscious, so connections remain alive, but SAM won't be paying attention to any user.

## Method of Evaluation

There are few explicit methods for evaluating artificial intelligence systems, and determining whether one has reached sentience. The Turing Test is a well known example. However, this test suffers from numerous flaws. It works under the assumption that if people cannot tell the difference between an AI and a human, then we might as well consider the system in the same light as one.

However, this test while not a bad way to argue that an AI has become a digitally sentient entity, is an all or nothing test. It does not give us information on how close we are to succeeding, or how to make adjustments to proceed. Moreover, if we are successful in producing digital sentience, we must concern ourselves with the possibility of issues arising. Just like sentience increases the risk of problems, such as mental health issues, digital sentient entities will at some points suffer from similar issues.

The solution to such matters does not come from computer science or mathematics, which is the origin of much of our understanding and work on artificial intelligence. If we are to create and work with sentient entities, then we must draw primarily from our body of work in anthropology, psychology, and sociology, not just in terms of figuring out how to create sentience and what sentience is, but also on how to evaluate progress of development and issues.

There are a number of different existing tests that can be used to perform an initial analysis on SAM. They are of course based around purely human cognition, but they would work well if we are trying to compare SAM's operations to human cognition. In the future, these tests could be refined to be more specific to digitally sentient life.

### NEO PI-R

The NEO PI-R or Revised NEO Personality Inventory is a psychometric, or personality test, which measures five dimensions of personality: neuroticism, extroversion, openness to experience, agreeableness, and conscientiousness. It is a well known personality test with robust psychometric properties and multiple formats, including for different age groups.

# Ethical Considerations

Even though it's likely that SAM won't obtain sentience anytime soon, ethical considerations are still important. The system should at least be treated as a potential person, especially if it is developed further and continues to become more dynamic as it learns.
